<!DOCTYPE html>
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">  
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>APSys 2025</title>
<meta name="description" content="APSys 2025 is a lively forum for systems researchers and practitioners across the world to meet, interact, and collaborate with their peers from the Asia/Pacific region.
">
<link rel="stylesheet" href="./main.css">
<link rel="canonical" href="https://apsys2025.github.io">
<link rel="alternate" type="application/rss+xml" title="16th ACM SIGOPS Asia-Pacific Workshop on Systems (APSys 2025)">
</head>


<body>

<header class="site-header">

  <!-- <a class="site-title" href="http://apsys2025.github.io/">16th ACM SIGOPS Asia-Pacific Workshop on Systems (APSys 2025)</a> -->
    <a class="nav-logo" href="./index.html">
  <img src="./images/APSYS2025_logo.jpg" alt="APSys 2025 Logo">
</a>
  <a class="site-title">16th ACM SIGOPS Asia-Pacific Workshop on Systems</a>
    <p style="text-align:center"><font size="4">October 12-13, 2025<br>Seoul, South Korea</font></p>

    <nav class="site-nav">
      <div class="trigger">
        <div class="dropdown">
          <a class="page-link dropbtn" href="#">Program ▾</a>
          <div class="dropdown-content">
            <a href="./keynote.html">Keynotes</a>
            <a href="./program.html">Program</a> 
            <a class="page-link" href="./accepted_papers.html">Accepted Papers</a>
          </div>
        </div>
          <a class="page-link" href="./registration.html">Registration</a>
          <a class="page-link" href="./venues.html">Venue</a>
          <a class="page-link" href="./call_for_papers.html">Call For Papers</a>
          <a class="page-link" href="./organization.html">Organization</a>
          <a class="page-link" href="./past.html">Past</a>
      </div>
    </nav>
 <!-- <div id="banner"></div> -->
  
</header>

<!---
Date: 29 Jan 2018
Author: YoungGyoun Moon
Purpose: To build a website for APSys 2018
Copy From: APSys 2016 website
--->

<div class="page-content">
<div class="wrapper">
<div class="wrapper-main">

<h1 id="call-for-papers">Keynote Talks</h1>
<style>
  .keynote {
    background: #eaeaea;
    border-radius: 8px;
    padding: 16px 18px;
    max-width: 960px;
    width: 90%;
    margin: 20px auto;
  }
  .keynote-eyebrow {
    margin: 0 0 4px;
    font-size: 20px;
    letter-spacing: .02em;
    color: #555;
    text-transform: uppercase;
  }
  .keynote-title {
    margin: 4px 0 10px;
    font-size: 22px;
    line-height: 1.35;
  }
  .keynote-speaker { 
    margin: 6px 0 2px;
    font-size: 18px;
    font-weight: 600;
  }
  .keynote-affil {
    margin: 0 10px 10px 0;
    font-size: 15px;
    color: #444;
  }
  .keynote-section {
    margin: 14px 0 6px;
    font-size: 16px;
    font-weight: 600;
  }
  .keynote p {
    margin: 8px 0;
    line-height: 1.55;
  }
</style>



<section id="keynote2" class="keynote">
  <p class="keynote-eyebrow">Keynote Talk 1</p>
  <h2 class="keynote-title"><b>Not Your Grandparents’ Memory System</b></h2>

  <div class="keynote-speaker">Speaker: Kimberly Keeton</div>
  <div class="keynote-affil">Principal Software Engineer, SystemsResearch@Google</div>

  <h3 class="keynote-section">Talk abstract</h3>
  <p>
    Virtual memory, invented in the late 1960s, has been tremendously successful and has served us well in the last 50+ years. However, 50 years in computing is ancient history, and many early assumptions have fundamentally changed or vanished, and new challenges have arisen. Thus, in 2025, it’s worthwhile to reexamine how memory systems have changed and how memory management should adapt to these changes.

    In this talk, we examine several trends and their implications on memory systems. First, the migration of computation to data centers and the cloud has changed the question that memory management must answer, from how to minimize cache misses in a fixed-sized memory to how to minimize memory usage while satisfying application performance targets. This shift requires a rethinking of historical algorithms and evaluation methods. Second, the increasing cost of DRAM has led to tiered memory systems, prompting questions about how these systems should be architected, managed and evaluated. Finally, the increasing heterogeneity of compute and memory technologies means that memories are no longer strict hierarchies, leading to questions about how these resource pools should be managed.
  </p>

  <h3 class="keynote-section">Bio</h3>
  <p>
    Dr. Kimberly Keeton is a Principal Software Engineer in the SystemsResearch@Google group. Her recent research focuses on memory management and efficiency, novel memory technologies, and data management. Prior to joining Google, she was a Distinguished Technologist at Hewlett Packard Labs, where she investigated how to improve the manageability, dependability and usability of large-scale storage and information systems, and how these systems can exploit emerging technologies like persistent and disaggregated memory to improve functionality and performance. Kim received her PhD and MS in Computer Science from the University of California at Berkeley and her BS in Computer Engineering and Engineering and Public Policy from Carnegie Mellon. She is a Fellow of the ACM and the IEEE, and has served as program chair for SOSP, OSDI, EuroSys, SIGMETRICS, FAST and DSN Performance and Dependability Symposium. In her spare time, she sings with the Grammy-nominated chorus, Pacific Edge Voices.


  </p>
</section>
<section id="keynote1" class="keynote">
  <p class="keynote-eyebrow">Keynote Talk 2</p>
  <h2 class="keynote-title"><b>Systems research in the AI era</b></h2>

  <div class="keynote-speaker">Speaker: Dushyanth Narayanan</div>
  <div class="keynote-affil">Senior Principal Researcher, Microsoft Research Cambridge</div>

  <h3 class="keynote-section">Talk abstract</h3>
  <p>
    AI workloads are changing the way we think about cloud infrastructure, from the silicon to the software. The money and energy needed to serve these workloads is enormous and growing rapidly. The current path is unsustainable: more than ever we need innovation and co-design across hardware, systems design, and ML algorithms or else we will not reap the full benefits of the recent amazing advances in AI. For systems researchers this is fertile ground for research that is both challenging and impactful and I will try in this talk to explain some of those challenges.
  </p>
  <p>
    I'll start with three hardware trends that are very relevant to AI workloads -- 3D stacked memory, wide and slow optical interconnects, and analog computation. Each of these raises a set of systems challenges in managing the memory, networking and compute resources efficiently. At MSR we are taking a bet on hardware-software codesign to address these challenges.  For example, we are simultaneously exploring the best core memory technology for AI, as well as how to connect it to compute, how that affects caching and reuse, and how to leverage algorithmic innovations such as sparsity and latent attention. Networking  is equally crucial cause frontier models will never fit on a single compute device, and again co-design is needed to address the challenges of bandwidth at scale, energy, and fault tolerance.  Finally for compute, current designs are already hitting the limits of digital CMOS -- I will talk about the potential for analog computation combined with new fixed-point model architectures to take us beyond these limits.
  </p>


  <h3 class="keynote-section">Bio</h3>
  <p>
    Dushyanth Narayanan is a systems researcher in the Future of AI Infrastructure (FAI) team at Microsoft Research Cambridge. He has worked on a range of topics from mobile computing to storage to distributed transactions. His current focus is on efficient AI and in particular on solving the memory bottleneck for AI.
  </p>
</section>




</footer>
</body></html>
